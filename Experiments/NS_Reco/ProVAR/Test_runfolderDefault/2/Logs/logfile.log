Module path:  Environments.NS_Reco NS_Reco
Dynamically loaded from:  <class 'Environments.NS_Reco.NS_Reco'>
Reward Amplitudes: [4.17022005e-01 7.20324493e-01 1.14374817e-04 3.02332573e-01
 1.46755891e-01] :: Avg 0.317309867282206 
Module path:  Src.Algorithms.ProVAR ProVAR
Dynamically loaded from:  <class 'Src.Algorithms.ProVAR.ProVAR'>
=====Configurations=====
 Namespace(NN_basis_dim='32', Policy_basis_dim='32', actor_lr=0.01, algo_name='ProVAR', base=0, batch_size=1000, buffer_size=1000, debug=True, delta=1, entropy_lambda=0.1, env_name='NS_Reco', experiment='Test_runfolder', extrapolator_basis='Poly', folder_suffix='Default', fourier_coupled=True, fourier_k=10, fourier_order=-1, gamma=0.99, gauss_std=1.5, gpu=0, hyper='default', importance_clip=10.0, inc=1, log_output='term_file', max_episodes=1000, max_inner=150, max_steps=500, optim='rmsprop', oracle=-1000, raw_basis=True, restore=False, save_count=10, save_model=True, seed=2, speed=2, state_lr=0.001, summary=True, swarm=False, timestamp='10|13|19:38:18')
Actions space: 5 :: State space: 1
State Low: tensor([0.]) :: State High: tensor([1.])
State features:  [('dummy_param', torch.Size([1]))]
Policy:  [('fc1.weight', torch.Size([5, 1])), ('fc1.bias', torch.Size([5]))]
0 :: Rewards -0.012 :: steps: 0.20 :: Time: 0.000(0.00072/step) :: Entropy : 0.000 :: Grads : [[], []]
5 :: Rewards -0.006 :: steps: 1.00 :: Time: 0.000(0.00034/step) :: Entropy : 0.000 :: Grads : [[], []]
10 :: Rewards 0.001 :: steps: 1.00 :: Time: 0.002(0.00164/step) :: Entropy : 0.000 :: Grads : [[0.0058618993, 0.0], []]
15 :: Rewards 0.117 :: steps: 1.00 :: Time: 0.005(0.00497/step) :: Entropy : 0.000 :: Grads : [[0.117709376, 0.0], []]
20 :: Rewards 0.245 :: steps: 1.00 :: Time: 0.010(0.00997/step) :: Entropy : 0.000 :: Grads : [[0.24684122, 0.0], []]
25 :: Rewards 0.320 :: steps: 1.00 :: Time: 0.008(0.00782/step) :: Entropy : 0.000 :: Grads : [[0.49113613, 0.0], []]
30 :: Rewards 0.387 :: steps: 1.00 :: Time: 0.009(0.00883/step) :: Entropy : 0.000 :: Grads : [[0.8938721, 0.0], []]
35 :: Rewards 0.457 :: steps: 1.00 :: Time: 0.010(0.00997/step) :: Entropy : 0.000 :: Grads : [[1.111594, 0.0], []]
40 :: Rewards 0.515 :: steps: 1.00 :: Time: 0.011(0.01139/step) :: Entropy : 0.000 :: Grads : [[1.3264552, 0.0], []]
45 :: Rewards 0.521 :: steps: 1.00 :: Time: 0.013(0.01272/step) :: Entropy : 0.000 :: Grads : [[1.6146787, 0.0], []]
50 :: Rewards 0.606 :: steps: 1.00 :: Time: 0.013(0.01321/step) :: Entropy : 0.000 :: Grads : [[1.964701, 0.0], []]
55 :: Rewards 0.660 :: steps: 1.00 :: Time: 0.014(0.01405/step) :: Entropy : 0.000 :: Grads : [[2.280265, 0.0], []]
60 :: Rewards 0.765 :: steps: 1.00 :: Time: 0.016(0.01551/step) :: Entropy : 0.000 :: Grads : [[2.798592, 0.0], []]
65 :: Rewards 0.750 :: steps: 1.00 :: Time: 0.016(0.01624/step) :: Entropy : 0.000 :: Grads : [[3.269453, 0.0], []]
70 :: Rewards 0.782 :: steps: 1.00 :: Time: 0.017(0.01746/step) :: Entropy : 0.000 :: Grads : [[3.5980766, 0.0], []]
75 :: Rewards 0.823 :: steps: 1.00 :: Time: 0.020(0.01983/step) :: Entropy : 0.000 :: Grads : [[3.949775, 0.0], []]
80 :: Rewards 0.931 :: steps: 1.00 :: Time: 0.019(0.01920/step) :: Entropy : 0.000 :: Grads : [[4.504929, 0.0], []]
85 :: Rewards 0.930 :: steps: 1.00 :: Time: 0.021(0.02064/step) :: Entropy : 0.000 :: Grads : [[4.9412374, 0.0], []]
90 :: Rewards 0.932 :: steps: 1.00 :: Time: 0.021(0.02140/step) :: Entropy : 0.000 :: Grads : [[5.2661815, 0.0], []]
95 :: Rewards 0.922 :: steps: 1.00 :: Time: 0.022(0.02239/step) :: Entropy : 0.000 :: Grads : [[5.5520296, 0.0], []]
100 :: Rewards 0.914 :: steps: 1.00 :: Time: 0.028(0.02769/step) :: Entropy : 0.000 :: Grads : [[5.7742567, 0.0], []]
105 :: Rewards 0.900 :: steps: 1.00 :: Time: 0.032(0.03245/step) :: Entropy : 0.000 :: Grads : [[5.961137, 0.0], []]
110 :: Rewards 0.892 :: steps: 1.00 :: Time: 0.026(0.02643/step) :: Entropy : 0.000 :: Grads : [[6.113858, 0.0], []]
115 :: Rewards 0.871 :: steps: 1.00 :: Time: 0.039(0.03917/step) :: Entropy : 0.000 :: Grads : [[6.2421656, 0.0], []]
120 :: Rewards 0.937 :: steps: 1.00 :: Time: 0.029(0.02941/step) :: Entropy : 0.000 :: Grads : [[6.4163437, 0.0], []]
125 :: Rewards 0.927 :: steps: 1.00 :: Time: 0.033(0.03262/step) :: Entropy : 0.000 :: Grads : [[6.6636605, 0.0], []]
130 :: Rewards 0.926 :: steps: 1.00 :: Time: 0.038(0.03781/step) :: Entropy : 0.000 :: Grads : [[6.8321595, 0.0], []]
135 :: Rewards 0.918 :: steps: 1.00 :: Time: 0.033(0.03271/step) :: Entropy : 0.000 :: Grads : [[6.981984, 0.0], []]
140 :: Rewards 0.907 :: steps: 1.00 :: Time: 0.034(0.03377/step) :: Entropy : 0.000 :: Grads : [[7.1054688, 0.0], []]
145 :: Rewards 0.899 :: steps: 1.00 :: Time: 0.042(0.04180/step) :: Entropy : 0.000 :: Grads : [[7.209371, 0.0], []]
150 :: Rewards 0.962 :: steps: 1.00 :: Time: 0.048(0.04806/step) :: Entropy : 0.000 :: Grads : [[7.3388085, 0.0], []]
155 :: Rewards 1.181 :: steps: 1.00 :: Time: 0.038(0.03795/step) :: Entropy : 0.000 :: Grads : [[7.917936, 0.0], []]
160 :: Rewards 1.174 :: steps: 1.00 :: Time: 0.040(0.03953/step) :: Entropy : 0.000 :: Grads : [[8.553607, 0.0], []]
165 :: Rewards 1.165 :: steps: 1.00 :: Time: 0.041(0.04093/step) :: Entropy : 0.000 :: Grads : [[9.029912, 0.0], []]
170 :: Rewards 1.168 :: steps: 1.00 :: Time: 0.041(0.04139/step) :: Entropy : 0.000 :: Grads : [[9.426809, 0.0], []]
175 :: Rewards 1.169 :: steps: 1.00 :: Time: 0.042(0.04247/step) :: Entropy : 0.000 :: Grads : [[9.7657795, 0.0], []]
180 :: Rewards 1.187 :: steps: 1.00 :: Time: 0.044(0.04367/step) :: Entropy : 0.000 :: Grads : [[10.045225, 0.0], []]
185 :: Rewards 1.178 :: steps: 1.00 :: Time: 0.045(0.04547/step) :: Entropy : 0.000 :: Grads : [[10.283137, 0.0], []]
190 :: Rewards 1.180 :: steps: 1.00 :: Time: 0.047(0.04692/step) :: Entropy : 0.000 :: Grads : [[10.483015, 0.0], []]
195 :: Rewards 1.188 :: steps: 1.00 :: Time: 0.049(0.04938/step) :: Entropy : 0.000 :: Grads : [[10.651168, 0.0], []]
200 :: Rewards 1.187 :: steps: 1.00 :: Time: 0.073(0.07317/step) :: Entropy : 0.000 :: Grads : [[10.794888, 0.0], []]
205 :: Rewards 1.155 :: steps: 1.00 :: Time: 0.053(0.05344/step) :: Entropy : 0.000 :: Grads : [[10.918635, 0.0], []]
210 :: Rewards 1.162 :: steps: 1.00 :: Time: 0.060(0.06031/step) :: Entropy : 0.000 :: Grads : [[11.024581, 0.0], []]
215 :: Rewards 1.166 :: steps: 1.00 :: Time: 0.053(0.05284/step) :: Entropy : 0.000 :: Grads : [[11.115755, 0.0], []]
220 :: Rewards 1.180 :: steps: 1.00 :: Time: 0.054(0.05361/step) :: Entropy : 0.000 :: Grads : [[11.195029, 0.0], []]
225 :: Rewards 1.176 :: steps: 1.00 :: Time: 0.055(0.05458/step) :: Entropy : 0.000 :: Grads : [[11.263438, 0.0], []]
230 :: Rewards 1.171 :: steps: 1.00 :: Time: 0.070(0.06997/step) :: Entropy : 0.000 :: Grads : [[11.321892, 0.0], []]
235 :: Rewards 1.157 :: steps: 1.00 :: Time: 0.062(0.06234/step) :: Entropy : 0.000 :: Grads : [[11.373915, 0.0], []]
240 :: Rewards 1.156 :: steps: 1.00 :: Time: 0.060(0.06028/step) :: Entropy : 0.000 :: Grads : [[11.419016, 0.0], []]
245 :: Rewards 1.163 :: steps: 1.00 :: Time: 0.060(0.06039/step) :: Entropy : 0.000 :: Grads : [[11.4584255, 0.0], []]
250 :: Rewards 1.157 :: steps: 1.00 :: Time: 0.062(0.06197/step) :: Entropy : 0.000 :: Grads : [[11.492915, 0.0], []]
